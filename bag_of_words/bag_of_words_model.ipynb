{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbef2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "## extract the descriptors from all images. ##\n",
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693bd2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('mylist1.txt','r')\n",
    "names = json.loads(f.read())\n",
    "f.close()\n",
    "f = open('mylist2.txt','r')\n",
    "labels = json.loads(f.read())\n",
    "f.close()\n",
    "f = open('mylist3.txt','r')\n",
    "categories = json.loads(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda49115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(centroids, img_descriptors):\n",
    "    n_centroids = centroids.shape[0]  # number of centroids found with the KMeans clustering #100\n",
    "    n_descriptors = img_descriptors.shape[0]  # number of descriptors extracted from the image #200\n",
    "    \n",
    "    # initialization of the bag of words (BoW) vector\n",
    "    # Note that the BoW vector has length equal to the number of cluster centroids\n",
    "    # The cluster centroids are indeed our visual words, and the BoW will be the histogram of these words found in the given image\n",
    "    bow_vector = np.zeros(n_centroids)  \n",
    "    \n",
    "    for i in range(n_descriptors):\n",
    "        for j in range(n_centroids):\n",
    "            if img_descriptors[i][j]==True: #if the feature is in the image (true in img_descriptor)\n",
    "                bow_vector[j]+=1            #bow_vector.shape => 100 (for each image)\n",
    "    return bow_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03275d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174716, 128)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the data structure that will contain all the descriptors\n",
    "descriptors = None\n",
    "# Loop over map images\n",
    "for img_name in names:\n",
    "\n",
    "    img = cv2.imread(os.path.join('../images/', img_name))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (kps, descriptors_img) = sift.detectAndCompute(gray, None)\n",
    "\n",
    "    if descriptors is None:\n",
    "        descriptors = descriptors_img\n",
    "    else:\n",
    "        descriptors = np.vstack( (descriptors, descriptors_img))\n",
    "               \n",
    "print(descriptors.shape)\n",
    "\n",
    "## CLUSTERING ##\n",
    "\n",
    "K = 100  # number of clusters (equivalent to the number of words) we want to estimate\n",
    "kmeans = KMeans(n_clusters=K, random_state=0, n_init=4)\n",
    "clusters = kmeans.fit(descriptors)  # we use the descriptors extracted from the map (training) images before\n",
    "centroids = clusters.cluster_centers_\n",
    "with open(\"kmeanmodel.pkl\",\"wb\") as f:\n",
    "    pickle.dump(kmeans,f)\n",
    "print(\"Shape of the centroids matrix: \", centroids.shape)\n",
    "print(\"We computed \", centroids.shape[0], \"centroids of lengh \", centroids.shape[1], \" (the same of the descriptor)\")\n",
    "# Rememeber: the centroids can be considered as the words that compose our documents \n",
    "# -> in this case the basic components of the images\n",
    "\n",
    "## BAG OF WORDS REPRESENTATION OF MAP IMAGES ## \n",
    "\n",
    "bow_map_images = None\n",
    "# loop over the images in the map set\n",
    "for img_name in names:\n",
    "    # load image\n",
    "    img = cv2.imread(os.path.join('../images/', img_name))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (kps, img_descriptors) = sift.detectAndCompute(gray, None)\n",
    "\n",
    "    # compute BoW representation of the image (using the basic 'words', i.e. centroinds, computed earlier)\n",
    "    bow = bag_of_words(centroids, img_descriptors)\n",
    "    # add the computed BoW vector to the set of map representations\n",
    "    if bow_map_images is None:\n",
    "        bow_map_images = bow\n",
    "    else:\n",
    "        bow_map_images = np.vstack( (bow_map_images, bow))\n",
    "        \n",
    "np.save(\"centroids.npy\", centroids)\n",
    "np.save(\"bow_map_images.npy\", bow_map_images)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd5bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
